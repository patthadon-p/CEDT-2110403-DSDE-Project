{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0c086b",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af503953",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19719dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce1491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add current directory to Python path for imports\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import findspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Add the parent directory (project root) to Python path so we can import from src\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d08655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "from src.utils import get_dot_env_path\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=get_dot_env_path())\n",
    "\n",
    "HADOOP_HOME = os.getenv(\"HADOOP_HOME\", \"\")\n",
    "SPARK_HOME = os.getenv(\"SPARK_HOME\", \"\")\n",
    "JAVA_HOME = os.getenv(\"JAVA_HOME\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1eeabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Python executable for PySpark\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "# Set Hadoop, Spark and Java home\n",
    "os.environ[\"HADOOP_HOME\"] = HADOOP_HOME\n",
    "os.environ[\"SPARK_HOME\"] = SPARK_HOME\n",
    "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
    "\n",
    "# Update system PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.join(HADOOP_HOME, \"bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e15fa0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize findspark\n",
    "findspark.init(SPARK_HOME)\n",
    "\n",
    "# Initialize Spark session (reuse existing session if available)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"CleansingData\")\n",
    "    .config(\"spark.executorEnv.PYTHONPATH\", project_root)\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e3b03",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7724a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------+-------------+--------------------+---------+----+------------+--------------------+\n",
      "|  ticket_id|               type|        organization|             comment|               photo|         photo_after|            coords|             address|subdistrict|district|     province|           timestamp|    state|star|count_reopen|       last_activity|\n",
      "+-----------+-------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------+-------------+--------------------+---------+----+------------+--------------------+\n",
      "|2021-FYJTFP|        {ความสะอาด}|          เขตบางซื่อ|             ขยะเยอะ|https://storage.g...|                NULL|100.53084,13.81865|12/14 ถนน กรุงเทพ...|       NULL|    NULL|กรุงเทพมหานคร|2021-09-03 19:51:...|เสร็จสิ้น|NULL|           0|2022-06-04 22:34:...|\n",
      "|2021-CGPMUN|{น้ำท่วม,ร้องเรียน}|เขตประเวศ,ฝ่ายโยธ...|น้ำท่วมเวลาฝนตกแล...|https://storage.g...|https://storage.g...|100.66709,13.67891|189 เฉลิมพระเกียร...|    หนองบอน|  ประเวศ|กรุงเทพมหานคร|2021-09-19 21:56:...|เสร็จสิ้น|   4|           0|2022-06-21 15:21:...|\n",
      "|2021-7XATFA|            {สะพาน}|             เขตสาทร|สะพานลอยปรับปรุงไ...|https://storage.g...|                NULL|100.52649,13.72060|191/1 ถนน สาทรเหน...|    ยานนาวา|    สาทร|กรุงเทพมหานคร|2021-09-26 12:03:...|เสร็จสิ้น|NULL|           0|2022-06-06 08:17:...|\n",
      "|2021-9U2NJT|          {น้ำท่วม}|เขตบางซื่อ,ฝ่ายโย...|             น้ำท่วม|https://storage.g...|https://storage.g...|100.53099,13.81853|12/14 ถนน กรุงเทพ...|       NULL|    NULL|กรุงเทพมหานคร|2021-10-14 17:45:...|เสร็จสิ้น|NULL|           0|2022-09-08 15:35:...|\n",
      "|2021-DVEWYM|      {น้ำท่วม,ถนน}|เขตลาดพร้าว,ฝ่ายโ...|ซอยลาดพร้าววังหิน...|https://storage.g...|                NULL|100.59165,13.82280|702 ถ. ลาดพร้าววั...|   ลาดพร้าว|ลาดพร้าว|กรุงเทพมหานคร|2021-12-09 19:29:...|เสร็จสิ้น|   5|           0|2022-08-12 14:18:...|\n",
      "|2021-4D9Y98|                 {}|เขตลาดพร้าว,การไฟ...|หน้าปากซอย ลาดพร้...|https://storage.g...|https://storage.g...|100.59131,13.80910|17/73 17/73 ถ. ลา...|   ลาดพร้าว|ลาดพร้าว|กรุงเทพมหานคร|2021-12-13 12:53:...|เสร็จสิ้น|NULL|           0|2023-03-14 19:09:...|\n",
      "|2021-7U9RED|                 {}|            เขตดุสิต|ยังไม่มีหน่วยงานไ...|https://storage.g...|https://storage.g...|100.50848,13.77832|627 ถนนสามเสน แขว...|      ดุสิต|   ดุสิต|กรุงเทพมหานคร|2021-12-17 15:46:...|เสร็จสิ้น|   5|           0|2023-05-17 13:11:...|\n",
      "|2021-8N9ZP8|        {ความสะอาด}|เขตประเวศ,ฝ่ายเทศ...|คนเอาขยะมาทิ้งจนก...|https://storage.g...|https://storage.g...|100.64690,13.67083|110 ซอย มีสุข แขว...|    หนองบอน|  ประเวศ|กรุงเทพมหานคร|2021-12-18 21:50:...|เสร็จสิ้น|   2|           0|2024-11-26 11:17:...|\n",
      "|2021-7K6QA3|                 {}|เขตประเวศ,ฝ่ายเทศ...|ระยะหลังๆ นี้ พบเ...|https://storage.g...|https://storage.g...|100.65617,13.72812|208/22 ถ. พัฒนากา...|     ประเวศ|  ประเวศ|กรุงเทพมหานคร|2021-12-22 06:03:...|เสร็จสิ้น|   2|           0|2022-06-24 13:32:...|\n",
      "|2021-8BTWZB|      {ท่อระบายน้ำ}|เขตประเวศ,ฝ่ายโยธ...|ขอแจ้งเรื่องท่อระ...|https://storage.g...|https://storage.g...|100.65440,13.68158|70 ซอย เฉลิมพระเก...|    หนองบอน|  ประเวศ|กรุงเทพมหานคร|2021-12-22 17:15:...|เสร็จสิ้น|   5|           0|2022-06-20 20:12:...|\n",
      "+-----------+-------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------+-------------+--------------------+---------+----+------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils import read_config_path\n",
    "\n",
    "# Load data using configuration file\n",
    "filepath = read_config_path(key=\"raw_data_path\")\n",
    "\n",
    "df = spark.read.csv(\n",
    "    filepath,\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    multiLine=True,\n",
    "    escape='\"',\n",
    "    quote='\"',\n",
    ")\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0d9bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50089666",
   "metadata": {},
   "source": [
    "## Testing Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea496f22",
   "metadata": {},
   "source": [
    "### Ingestion Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines_spark import IngestionPreprocessorSpark\n",
    "\n",
    "preprocessor = IngestionPreprocessorSpark()\n",
    "cleaned_df = preprocessor.transform(df)\n",
    "\n",
    "cleaned_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeba973",
   "metadata": {},
   "source": [
    "### Date Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines_spark import DateTransformerSpark\n",
    "\n",
    "dt = DateTransformerSpark()\n",
    "df_transformed = dt.transform(df)\n",
    "\n",
    "df_transformed.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc387c1c",
   "metadata": {},
   "source": [
    "### Province Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b47b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines_spark import ProvinceTransformerSpark\n",
    "\n",
    "pt = ProvinceTransformerSpark()\n",
    "df_transformed = pt.transform(df)\n",
    "\n",
    "df_area_count = df_transformed.groupBy(\"province\").count()\n",
    "df_area_count.orderBy(\"count\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52287be2",
   "metadata": {},
   "source": [
    "### District and Subdistrict Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines_spark import DistrictSubdistrictTransformerSpark\n",
    "\n",
    "dst = DistrictSubdistrictTransformerSpark()\n",
    "df_transformed = dst.transform(df)\n",
    "\n",
    "df_area_count = df_transformed.groupBy(\"district\", \"subdistrict\").count()\n",
    "df_area_count.orderBy(\"count\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8299dbca",
   "metadata": {},
   "source": [
    "### Coordinate Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.pipelines import CoordinateTransformer\n",
    "\n",
    "# ct = CoordinateTransformer()\n",
    "# df_transformed = pd.DataFrame(ct.fit_transform(df))\n",
    "\n",
    "# df_transformed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c8bd3",
   "metadata": {},
   "source": [
    "### Address Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748381c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines_spark import AddressTransformerSpark\n",
    "\n",
    "at = AddressTransformerSpark()\n",
    "df_transformed = at.transform(df)\n",
    "\n",
    "df_transformed.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069098e8",
   "metadata": {},
   "source": [
    "### State to Status Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf73e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines_spark import StateToStatusTransformerSpark\n",
    "\n",
    "stst = StateToStatusTransformerSpark()\n",
    "df_transformed = stst.transform(df_transformed)\n",
    "\n",
    "df_status_count = df_transformed.groupBy(\"status\").count()\n",
    "df_status_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa0a03",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c8d67",
   "metadata": {},
   "source": [
    "## Applying Cleansing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc062df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+--------------------+--------------------+------------------+--------------------+-----------+--------+-------------+--------------+---------------+--------------+------------------+-------------------+------------------+------+\n",
      "|  ticket_id|               type|        organization|             comment|            coords|             address|subdistrict|district|     province|timestamp_date|timestamp_month|timestamp_year|last_activity_date|last_activity_month|last_activity_year|status|\n",
      "+-----------+-------------------+--------------------+--------------------+------------------+--------------------+-----------+--------+-------------+--------------+---------------+--------------+------------------+-------------------+------------------+------+\n",
      "|2021-CGPMUN|{น้ำท่วม,ร้องเรียน}|เขตประเวศ,ฝ่ายโยธ...|น้ำท่วมเวลาฝนตกแล...|100.66709,13.67891|189 เฉลิมพระเกียร...|    หนองบอน|  ประเวศ|กรุงเทพมหานคร|            19|              9|          2021|                21|                  6|              2022|  done|\n",
      "|2021-7XATFA|            {สะพาน}|             เขตสาทร|สะพานลอยปรับปรุงไ...|100.52649,13.72060|191/1 ถนน สาทรเหน...|    ยานนาวา|    สาทร|กรุงเทพมหานคร|            26|              9|          2021|                 6|                  6|              2022|  done|\n",
      "|2021-DVEWYM|      {น้ำท่วม,ถนน}|เขตลาดพร้าว,ฝ่ายโ...|ซอยลาดพร้าววังหิน...|100.59165,13.82280|702 ถ. ลาดพร้าววั...|   ลาดพร้าว|ลาดพร้าว|กรุงเทพมหานคร|             9|             12|          2021|                12|                  8|              2022|  done|\n",
      "|2021-4D9Y98|                 {}|เขตลาดพร้าว,การไฟ...|หน้าปากซอย ลาดพร้...|100.59131,13.80910|17/73 17/73 ถ. ลา...|   ลาดพร้าว|ลาดพร้าว|กรุงเทพมหานคร|            13|             12|          2021|                14|                  3|              2023|  done|\n",
      "|2021-7U9RED|                 {}|            เขตดุสิต|ยังไม่มีหน่วยงานไ...|100.50848,13.77832|627 ถนนสามเสน แขว...|      ดุสิต|   ดุสิต|กรุงเทพมหานคร|            17|             12|          2021|                17|                  5|              2023|  done|\n",
      "|2021-8N9ZP8|        {ความสะอาด}|เขตประเวศ,ฝ่ายเทศ...|คนเอาขยะมาทิ้งจนก...|100.64690,13.67083|110 ซอย มีสุข แขว...|    หนองบอน|  ประเวศ|กรุงเทพมหานคร|            18|             12|          2021|                26|                 11|              2024|  done|\n",
      "|2021-7K6QA3|                 {}|เขตประเวศ,ฝ่ายเทศ...|ระยะหลังๆ นี้ พบเ...|100.65617,13.72812|208/22 ถ. พัฒนากา...|     ประเวศ|  ประเวศ|กรุงเทพมหานคร|            22|             12|          2021|                24|                  6|              2022|  done|\n",
      "|2021-8BTWZB|      {ท่อระบายน้ำ}|เขตประเวศ,ฝ่ายโยธ...|ขอแจ้งเรื่องท่อระ...|100.65440,13.68158|70 ซอย เฉลิมพระเก...|    หนองบอน|  ประเวศ|กรุงเทพมหานคร|            22|             12|          2021|                20|                  6|              2022|  done|\n",
      "|2021-AKJBCU|                 {}|เขตประเวศ,ฝ่ายโยธ...|แจ้งเรื่องพื้นผิว...|100.64844,13.68735|55 ถนน ศรีนครินทร...|    หนองบอน|  ประเวศ|กรุงเทพมหานคร|            23|             12|          2021|                28|                  9|              2022|  done|\n",
      "|2021-EQWYWT|        {ความสะอาด}|เขตประเวศ,สำนักสิ...|ปัญหากลิ่นขยะจากโ...|100.68837,13.71887|22/1 ซอย อ่อนนุช ...|     ประเวศ|  ประเวศ|กรุงเทพมหานคร|            28|             12|          2021|                12|                  7|              2022|  done|\n",
      "+-----------+-------------------+--------------------+--------------------+------------------+--------------------+-----------+--------+-------------+--------------+---------------+--------------+------------------+-------------------+------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.pipelines_spark import CleansingPipelineSpark\n",
    "\n",
    "cleansing_pipeline = CleansingPipelineSpark()\n",
    "df_cleansed = cleansing_pipeline.transform(df)\n",
    "\n",
    "df_cleansed.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4c51d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticket_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- organization: string (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- coords: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- subdistrict: string (nullable = true)\n",
      " |-- district: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- timestamp_date: integer (nullable = true)\n",
      " |-- timestamp_month: integer (nullable = true)\n",
      " |-- timestamp_year: integer (nullable = true)\n",
      " |-- last_activity_date: integer (nullable = true)\n",
      " |-- last_activity_month: integer (nullable = true)\n",
      " |-- last_activity_year: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleansed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99667d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Define base data directory and final file path\n",
    "base_data_dir = os.path.join(\"..\", \"data\", \"processed\")\n",
    "temp_output_dir = os.path.join(base_data_dir, \"cleansed_data_spark-temp\")\n",
    "\n",
    "final_file = os.path.join(base_data_dir, \"cleansed_data_spark.csv\")\n",
    "\n",
    "# Write to single partition (one CSV file)\n",
    "df_cleansed.coalesce(1).write.csv(temp_output_dir, header=True, mode=\"overwrite\")\n",
    "\n",
    "# Find the generated part file inside the output directory\n",
    "for filename in os.listdir(temp_output_dir):\n",
    "    if filename.startswith(\"part-\") and filename.endswith(\".csv\"):\n",
    "        part_file = os.path.join(temp_output_dir, filename)\n",
    "        shutil.move(part_file, final_file)\n",
    "        break\n",
    "\n",
    "shutil.rmtree(temp_output_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78ef48",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
